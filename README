============================================================================
dimarray: array with labelled dimensions and axes, metadata and NaN handling
============================================================================

Forget the underlying array shape and concentrate on what you aim at doing !

Inspired by (but does not rely on) pandas:

    * behave like a numpy array (operations, transformations)
    * ...and to a certain extent like a dictionary
    * labelled axes, NaN handling
    * (quite) pretty printing
    * align along axis values in operations
    * `values` and `axes` attributes, `loc`, `iloc`, `xs` methods
    * GroupedAxis object similar to pandas MultiIndex

But generalized to any dimension and augmented with new features:

    * intuitive multi-dimensional slicing/reshaping/transforms by axis name
    * expand method to repeat/broadcast an array along new dimensions
      ==> arithmetics between arrays of different dimensions 
    * group/ungroup methods to flatten any subset of dimensions (GroupedAxis)
      ==> mean, sum, cumsum and so on applicable on any subset of dimensions
    * support axis-based weights as user-defined array or function on axis values 
      ==> mean/var/std can be weighted
    * natural netCDF I/O  via netCDF4 python module (requires HDF5, netCDF4)

Yet simpler with more control left to user (most attributes are non-protected, 
e.g. `values` can be overwritten), and organized around a small number of 
classes and methods:

    * Dimarray			: main data structure (see alias `array`)
    * Dataset		    	: ordered dictionary of Dimarray objects
    * read, write, summary      : netCDF I/O (Dimarray and Dataset methods)
    * Axis, Axes, GroupedAxis   : axis and indexing (under the hood)

And for things pandas does better (low-dimensional data analysis, `groupby`, 
I/O formats, etc...), just export via to_pandas() method (up to 4-D) (only
if pandas is installed of course - otherwise dimarray does not rely on pandas)


Get started
-----------

>>> import numpy as np
>>> from dimarray import Dimarray
>>> import dimarray as da

Define some dummy data representing 3 items "a", "b" and "c" over 5 years:

>>> np.random.seed(0) # just for the reproductivity of the examples below
>>> values = np.random.randn(3,5)

Defining a Dimarray from there is pretty straightforward

>>> a = Dimarray(values)   # fully automatic labelling
>>> a = Dimarray(values, 'items', 'time')  # axis values assumed [0, 1, 2,...]
>>> a = Dimarray(values, list("abc"), np.arange(1950,1955)) # "x0","x1" 
>>> a = Dimarray(values, ('items',list("abc")), ('time',np.arange(1950,1955)))  # all labels
>>> a    
dimarray: 15 non-null elements (0 null)
dimensions: 'items', 'time'
0 / items (3): a to c
1 / time (5): 1950 to 1954
array([[ 1.76405235,  0.40015721,  0.97873798,  2.2408932 ,  1.86755799],
       [-0.97727788,  0.95008842, -0.15135721, -0.10321885,  0.4105985 ],
       [ 0.14404357,  1.45427351,  0.76103773,  0.12167502,  0.44386323]])

For convenience, it is also possible to define an array via keyword arguments
(but note this is unambiguous only when axes have different size, see tutorial)

>>> b = Dimarray.from_kw(values, items=list("abc"), time=np.arange(1950,1955))
>>> np.all(a == b)
True

Can access underlying numpy array via `values` attributes

>>> a.values  # doctest: +ELLIPSIS
array(...)

And the axes, too:

>>> a.time
array([1950, 1951, 1952, 1953, 1954])
>>> a.items
array(['a', 'b', 'c'], dtype=object)
>>> np.all( a.time == a.axes["time"].values )
True

Easy slicing (xs for cross-section):

>>> a.xs(time=1952)
>>> a.xs(time=1952, items="b")
>>> a.xs(time=(1952,1954))
>>> a[:, 1952:1954] == a.xs(time=(1952,1954))
True
>>> a.iloc[:, 2:5] # integer access

Arithmetics with reshaping and axis alignment

>>> ts = da.array(np.random.randn(10), time=np.arange(1950, 1955)) # alias for Dimarray.from_kw
>>> a * ts   # not commutative !  # doctest: +ELLIPSIS
dimarray: 15 non-null elements (0 null)
dimensions: 'items', 'time'
0 / items (3): a to c
1 / time (5): 1950 to 1954
array(...)
>>> mymap = da.array(np.random.randn(5,10), lon=np.linspace(0,360,10), lat=np.linspace(-90.90,5))
>>> mycube = mymap * ts   # doctest: +ELLIPSIS
>>> mycube
...
dimensions: 'lat', 'lon', 'time'
0 / lat (5): 0. to 360.
1 / lon (10): -90. to 90.
2 / time (5): 1950 to 1954
array(...)

All numpy transforms work (with NaN checking)

>>> mycube.mean(axis="time") 

>>> a.values.mean(axis=1) == a.mean(axis="time").values  
True

Can also provide a subset of several dimensions as argument to operate on flattened array.

>>> mycube.mean(axis=("lat","lon"))

NetCDF I/O

>>> a.write("test.nc","myvar") # write to netCDF4
>>> da.summary("test.nc") # check the content
>>> dataset = da.read("test.nc") # read in a Dataset class
>>> dataset["myvar"]
>>> a
>>> dataset["myvar"] == a
True

Easy interfacing with pandas

>>> a.to_pandas()
time       1950      1951      1952      1953      1954
items                                                  
a      1.764052  0.400157  0.978738  2.240893  1.867558
b     -0.977278  0.950088 -0.151357 -0.103219  0.410599
c      0.144044  1.454274  0.761038  0.121675  0.443863

>>> a.to_pandas().plot()  # doctest: +ELLIPSIS
...
More complete documentation will follow...
